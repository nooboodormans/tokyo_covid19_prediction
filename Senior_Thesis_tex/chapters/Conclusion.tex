\section{Discussion And Future Works}

\subsection{Discussion}
\subsubsection{The "Initial spike" Issue}
In the result shown in Section 3, some neural network model was able to produce an "intuitive" prediction model such as the univariate prediction of 80 days using LSTM model in Figure \ref{fig:DL_Uni_80}, and the univariate prediction of 40 days using GRU model in Figure \ref{fig:DL_Uni_40}. However, most of the prediction plots included a spike for the first value of prediction, which looks very odd to say the least. The factors which causes this issue is still a mystery since, the used dataset and the methodology does not differ between other iterations (including epochs and batch number). Therefore, cracking down on the reason behind the calculation process which forms this "mountain" will be a big obstacle to make the result of the prediction more practical. 

\subsubsection{The Multiple Feature Issue}
In this paper, we delved into two prediction processes, which are Univariate prediction and Multivariate Prediction. Comparing the results from different processes, the Univariate prediction almost always had a lower RMSE than the Multivariate prediction. This seems to be intuitively strange, since we expect a better result when we have more information to refer to. There is a possibility where some interdependency should be referred to before rendering all the dataset into a single model. In this paper, the selection and inclusion of features were done solely on the correlation values. A more careful consideration on what features should be included in the model should be done. 

\subsubsection{Lack of Consideration of Layers}
In this paper, LSTM and GRU, which are one of the most complicated neural network models are being used. Therefore, there should be more careful consideration when adding layers and choosing the hyperparamters since it is a very sensitive system. The model was shaped based on separate information found on the internet, which lacks reliability on the model itself. Therefore, a more careful approach of selecting hyperparameters are needed. 

\subsection{Future Works}
COVID-19 prediction is a harsh task to start with. With multiple variables intertwining with each other and some unobservable factors which contributes to the spread of the virus. Therefore, from a data science approach, it is imperative to go deep down on the data generation process to extract and evaluate relevant datasets that effectively tackles the research question at hand. Therefore, more attention is needed on the Public Health terminology and become aware of how the numbers are generated. This point also connects to the discussion point 4.1.2 where the interdependency between multiple variables should be considered when making a predictive model. 

This paper was able to construct the advanced deep learning methods using the Keras library \citep{keras} which is enriched with handy deep learning methods. However, there are some drawbacks to the blackbox nature of this library, where I cannot review the specific calculation affecting my output. To be specific, my result have produced many "mountain-shaped" results which was counterintuitive, but had no way to figure out how the data was being computed. Therefore, to excel more on the development of accurate prediction models, there is a need for me to start from the base and see how the parameters are being computed. 